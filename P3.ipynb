{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Submission\n",
    "\n",
    "Continuous Control for the Udacity Ud893 Deep Reinforcement Learning Nanodegree (DRLND)\n",
    "\n",
    "## Imports and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../python\")\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unity Environment\n",
    "\n",
    "Note that if your operating system is Windows (64-bit), the Unity environment is included and you can run the below environment instantiation cell.  \n",
    "\n",
    "However, if you're using a different operating system, download the file you require from one of the following links:\n",
    "\n",
    "- Linux: [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/Reacher_Linux.zip)\n",
    "- Mac OSX: [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/Reacher.app.zip)\n",
    "- Windows (32-bit): [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/Reacher_Windows_x86.zip)\n",
    "\n",
    "Then, place the file in the main project directory folder and unzip (or decompress) the file.  Modify the file_name in the below cell and then run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Tennis_Windows_x86_64/Tennis.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Default Brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training Loop Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def training_loop(agent, n_episodes=7000, max_t=3000):  \n",
    "    \"\"\"DDPG Training Loop\n",
    "    Params\n",
    "    ======\n",
    "        agent (function): agent function\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "    \"\"\"\n",
    "    \n",
    "    model_dir = os.getcwd()+\"/model_dir\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations              # get the current state\n",
    "        agent.reset()\n",
    "        score = np.zeros(len(env_info.agents))\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state)\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations      # get the next state\n",
    "            reward = env_info.rewards                      # get the reward\n",
    "            done = env_info.local_done                     # see if episode has finished\n",
    "            agent.step(state, action, reward, next_state, done, t)\n",
    "            state = np.copy(next_state)\n",
    "            score += reward\n",
    "            if np.any(done):\n",
    "                break\n",
    "        scores_window.append(np.amax(score))       # save most recent score\n",
    "        scores.append(np.amax(score))\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.4f}\\tScore: {}\\tTime: {}'.format(i_episode, np.mean(scores_window), score, datetime.now()-start_time), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.4f}\\tScore: {}\\tTime: {}'.format(i_episode, np.mean(scores_window), score, datetime.now()-start_time))\n",
    "\n",
    "            save_dict_list = []\n",
    "            for i in range(len(env_info.agents)):\n",
    "                save_dict = {'actor_params': agent.actor_local[i].state_dict(),\n",
    "                             'actor_optim_params': agent.actor_optimizer[i].state_dict(),\n",
    "                             'critic_params': agent.critic_local[i].state_dict(),\n",
    "                             'critic_optim_params': agent.critic_optimizer[i].state_dict()}\n",
    "                save_dict_list.append(save_dict)\n",
    "            torch.save(save_dict_list,\n",
    "                       os.path.join(model_dir, 'episode-{}.pt'.format(i_episode)))                            \n",
    "            \n",
    "            \n",
    "        if np.mean(scores_window)>=0.5:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.4f}'.format(i_episode, np.mean(scores_window)))\n",
    "            \n",
    "            save_dict_list = []\n",
    "            for i in range(len(env_info.agents)):\n",
    "                save_dict = {'actor_params': agent.actor_local[i].state_dict(),\n",
    "                             'actor_optim_params': agent.actor_optimizer[i].state_dict(),\n",
    "                             'critic_params': agent.critic_local[i].state_dict(),\n",
    "                             'critic_optim_params': agent.critic_optimizer[i].state_dict()}\n",
    "                save_dict_list.append(save_dict)\n",
    "                torch.save(save_dict_list,\n",
    "                           os.path.join(model_dir, 'final-episode.pt'))                \n",
    "            \n",
    "            \n",
    "            break\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MADDPG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Parameters:\n",
      "Number of agents: 2\n",
      "lr_a: 0.0001\n",
      "lr_c: 0.001\n",
      "weight decay: 0\n",
      "fc1_units: 400\n",
      "fc2_units: 300\n",
      "Episode 100\tAverage Score: 0.0050\tScore: [ 0.   -0.01]\tTime: 0:02:11.167774\n",
      "Episode 200\tAverage Score: 0.0040\tScore: [ 0.   -0.01]\tTime: 0:04:55.340351\n",
      "Episode 300\tAverage Score: 0.0040\tScore: [ 0.   -0.01]\tTime: 0:07:40.405865\n",
      "Episode 400\tAverage Score: 0.0000\tScore: [ 0.   -0.01]\tTime: 0:10:23.379763\n",
      "Episode 500\tAverage Score: 0.0000\tScore: [ 0.   -0.01]\tTime: 0:13:15.618006\n",
      "Episode 600\tAverage Score: 0.0066\tScore: [ 0.   -0.01]\tTime: 0:16:33.959479\n",
      "Episode 700\tAverage Score: 0.0180\tScore: [-0.01  0.  ]\tTime: 0:20:10.362165\n",
      "Episode 800\tAverage Score: 0.0310\tScore: [0.3  0.19]\tTime: 0:25:04.26602298\n",
      "Episode 900\tAverage Score: 0.0219\tScore: [ 0.   -0.01]\tTime: 0:29:17.293094\n",
      "Episode 1000\tAverage Score: 0.0488\tScore: [ 0.1  -0.01]\tTime: 0:34:26.189568\n",
      "Episode 1100\tAverage Score: 0.0952\tScore: [ 0.1  -0.01]\tTime: 0:42:13.826018\n",
      "Episode 1200\tAverage Score: 0.0955\tScore: [0.2  0.19]\tTime: 0:49:33.25012251\n",
      "Episode 1300\tAverage Score: 0.1016\tScore: [0.1  0.09]\tTime: 0:57:22.55342028\n",
      "Episode 1400\tAverage Score: 0.0933\tScore: [0.1  0.09]\tTime: 1:05:34.26531007\n",
      "Episode 1500\tAverage Score: 0.0910\tScore: [-0.01  0.1 ]\tTime: 1:13:42.513754\n",
      "Episode 1600\tAverage Score: 0.0979\tScore: [ 0.1  -0.01]\tTime: 1:22:05.156326\n",
      "Episode 1700\tAverage Score: 0.1016\tScore: [0.09 0.2 ]\tTime: 1:30:24.93179821\n",
      "Episode 1800\tAverage Score: 0.1227\tScore: [0.2  0.09]\tTime: 1:41:30.40608853:52.192120\n",
      "Episode 1900\tAverage Score: 0.1365\tScore: [0.1  0.09]\tTime: 1:53:52.17820710:36.925301\n",
      "Episode 2000\tAverage Score: 0.1515\tScore: [0.09 0.2 ]\tTime: 2:08:15.47525267:34.784494\n",
      "Episode 2100\tAverage Score: 0.1995\tScore: [0.09 0.2 ]\tTime: 2:26:07.57786589:47.431046\n",
      "Episode 2200\tAverage Score: 0.2215\tScore: [0.1  0.09]\tTime: 2:46:26.50662145:02.805147\n",
      "Episode 2300\tAverage Score: 0.3236\tScore: [1.19000002 1.30000002]\tTime: 3:16:31.415918\n",
      "Episode 2338\tAverage Score: 0.5140\tScore: [2.20000003 2.19000003]\tTime: 3:40:00.193557\n",
      "Environment solved in 2338 episodes!\tAverage Score: 0.5140\n",
      "Time:  3:40:00.226555\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from maddpg_agent import Agent\n",
    "\n",
    "agent = Agent(num_agents=2, state_size=24, action_size=2, random_seed=2, lr_a=1e-4, lr_c=1e-3,weight_decay=0, fc1_units=400, fc2_units=300)\n",
    "\n",
    "start = datetime.now()\n",
    "scores = training_loop(agent)\n",
    "end = datetime.now()\n",
    "time_taken = end - start\n",
    "print('Time: ',time_taken) \n",
    "\n",
    "# plot the scores\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episodes')\n",
    "plt.title('MADDPG Agent')\n",
    "plt.show()\n",
    "\n",
    "# purposely left commented.  Leave as is.\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Smart Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2\tStep: 400\tScore: [1.00000001 1.00000001]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "from model import Actor\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, random_seed, fc1_units=400, fc2_units=300):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            random_seed (int): random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(random_seed)\n",
    "\n",
    "        self.actor_local = Actor(\n",
    "            state_size, action_size, random_seed, fc1_units=fc1_units, fc2_units=fc2_units).to(device)\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "\n",
    "        action = np.zeros(self.action_size)\n",
    "        state.resize(1, self.state_size)  # reshape for batch processing\n",
    "        state = torch.from_numpy(state).float().to(device)\n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action = self.actor_local(state).cpu().data.numpy()\n",
    "        self.actor_local.train()\n",
    "        return np.clip(action, -1, 1)\n",
    "    \n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "num_agents = len(env_info.agents)\n",
    "\n",
    "# create 2 agents\n",
    "agent = [Agent(state_size=24, action_size=2, random_seed=2, fc1_units=400, fc2_units=300) for _ in range(num_agents)]\n",
    "\n",
    "# load each agent\n",
    "agent_file = torch.load('model_dir/final-episode.pt', map_location='cpu')\n",
    "for i in range(num_agents):\n",
    "    agent[i].actor_local.load_state_dict(agent_file[i]['actor_params'])\n",
    "    \n",
    "episodes = 1\n",
    "\n",
    "for i in range(episodes):\n",
    "    env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "    state = env_info.vector_observations            # get the current state\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    for j in range(400):\n",
    "        actions = np.zeros([2, 2])\n",
    "        for i in range(num_agents):\n",
    "            actions[i] = agent[i].act(state[i])\n",
    "        env_info = env.step(actions)[brain_name]        # send the action to the environment\n",
    "        state = env_info.vector_observations   # get the next state\n",
    "        reward = env_info.rewards                   # get the reward\n",
    "        done = env_info.local_done                # see if episode has finished                    \n",
    "        if np.any(done):\n",
    "            break\n",
    "        scores += reward\n",
    "        print('\\rEpisode: {}\\tStep: {}\\tScore: {}'.format(i+1, j+1, scores), end=\"\")\n",
    "    print('\\rEpisode: {}\\tStep: {}\\tScore: {}'.format(i+1, j+1, scores))\n",
    "        \n",
    "# purposely left commented.  Leave as is.\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
